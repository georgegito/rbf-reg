{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras import Input\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def ComputeMaxDistance(X1, X2):\n",
    "    max_dist = 0\n",
    "    for x1 in X1:\n",
    "        for x2 in X2:\n",
    "            dist = distance.euclidean(x1, x2)\n",
    "            max_dist = max(dist, max_dist)\n",
    "    return max_dist\n",
    "\n",
    "def RBF_kernel(inputs, centers, sigma):\n",
    "  X_ = tf.expand_dims(inputs, axis=1)\n",
    "  C_ = tf.expand_dims(tf.transpose(centers), axis=0)\n",
    "  D_ = X_ - C_\n",
    "  return tf.exp(-tf.norm(D_, axis=2)**2) / (2 * sigma**2) \n",
    "\n",
    "class RBF(keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, num_units):\n",
    "    self.num_units = num_units\n",
    "    super(RBF, self).__init__()\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.centers = self.add_weight(shape=(input_shape[1], self.num_units), initializer=tf.initializers.RandomNormal, trainable=False) # TODO use custom initializer\n",
    "    self.sigma = self.add_weight(shape=(1, 1), initializer=tf.initializers.RandomNormal, trainable=False) # TODO use custom initializer\n",
    "    super(RBF, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return RBF_kernel(inputs, self.centers, self.sigma)\n",
    "\n",
    "  def get_config(self):\n",
    "    base_config = super(RBF, self).get.config\n",
    "    base_config['num_units'] = self.num_units\n",
    "    return base_config\n",
    "\n",
    "  def compute_params(self, inputs):\n",
    "    kmeans = KMeans(n_clusters=self.num_units, random_state=0, copy_x=True).fit(inputs)\n",
    "    self.centers = kmeans.cluster_centers_\n",
    "    d_max = ComputeMaxDistance(self.centers, self.centers)\n",
    "    self.sigma = d_max / (math.sqrt(2 * self.centers.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras import Input\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "import utils\n",
    "import rbf_layer\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                   read data                                  #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "data = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "# data = \"boston.csv\"\n",
    "raw_df = pd.read_csv(data, sep=\"\\s+\", skiprows=22, header=None)\n",
    "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "y = raw_df.values[1::2, 2]\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                normalize data                                #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "preprocessing.scale(X, copy=False)\n",
    "preprocessing.scale(y, copy=False)\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                      split data to training and testing                      #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=0)\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "hidden_size = int(0.1 * n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_layer_ = RBF(hidden_size)\n",
    "rbf_layer_.compute_params(X_train)\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Input(shape=(13,)))\n",
    "model.add(rbf_layer_)\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rbf_2 (RBF)                 (None, 37)                482       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 304       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 786\n",
      "Trainable params: 304\n",
      "Non-trainable params: 482\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.8284271247461903, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "a = tf.Variable(np.array([[1., 2., 3.], [4., 5., 6.]]))\n",
    "b = tf.Variable(np.array([[1., 2., 3.], [4., 3., 4.]]))\n",
    "\n",
    "\n",
    "def euclideanDistance(x, y):\n",
    "    dist = tf.sqrt(tf.reduce_sum(tf.square(x - y), 1))\n",
    "    return dist\n",
    "\n",
    "d = euclideanDistance(a, b)\n",
    "\n",
    "print(tf.norm(a-b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45ed4a67b71b46dfc239d393e2e8571aa6d1d9599e857137f38810a72dcdb16b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
