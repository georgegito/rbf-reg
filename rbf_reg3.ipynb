{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def ComputeMaxDistance(X1, X2):\n",
    "    max_dist = 0\n",
    "    for x1 in X1:\n",
    "        for x2 in X2:\n",
    "            dist = distance.euclidean(x1, x2)\n",
    "            max_dist = max(dist, max_dist)\n",
    "    return max_dist\n",
    "\n",
    "def RBF_kernel(x, centers, sigma):\n",
    "  # res = []\n",
    "  # for c in centers:\n",
    "    # res.append(math.exp((-np.linalg.norm(x - c)**2) / (2*sigma**2)))\n",
    "  # res = [math.exp(-np.linalg.norm(x - c)**2) / (2 * sigma**2) for c in centers]\n",
    "  res = [math.exp(-np.linalg.norm(x - c)**2 / (2 * sigma**2)) for c in centers]\n",
    "  return res\n",
    "\n",
    "def RBF_layer_output(x, centers, sigma):\n",
    "  # res = []\n",
    "  # for x_ in x: \n",
    "  #   res.append(RBF_kernel(x_, centers, sigma))\n",
    "  # res = [RBF_kernel(x_, centers, sigma) for x_ in x]\n",
    "  # res = [0 for x_ in x]\n",
    "  res = [RBF_kernel(x_, centers, sigma) for x_ in x]\n",
    "\n",
    "  return res\n",
    "\n",
    "class RBF(keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, num_units):\n",
    "    self.num_units = num_units\n",
    "    super(RBF, self).__init__()\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    # shape1 = tf.TensorShape((input_shape[1], self.num_units))\n",
    "    # shape2 = tf.TensorShape((1, self.num_units))\n",
    "    self.centers = self.add_weight(shape=(input_shape[1], self.num_units), initializer=tf.initializers.RandomNormal, trainable=False) # TODO use custom initializer\n",
    "    self.sigma = self.add_weight(shape=(1, self.num_units), initializer=tf.initializers.RandomNormal, trainable=False) # TODO use custom initializer\n",
    "    # self.betas = np.ones(self.num_units) / (2 * (sigma**2))\n",
    "    # self.sigma    = self.add_weight(shape=1, initializer=tf.initializers.RandomNormal, trainable=False)\n",
    "    super(RBF, self).build(input_shape)\n",
    "  \n",
    "  def call(self, inputs):\n",
    "    D = inputs - tf.transpose(self.centers)\n",
    "    print(D)\n",
    "    return tf.exp(-tf.norm(D, axis=1)**2) / (2 * self.sigma[0]**2) # TODO change sigma[0]\n",
    "\n",
    "  def get_config(self):\n",
    "    base_config = super(RBF, self).get.config\n",
    "    base_config['num_units'] = self.num_units\n",
    "    return base_config\n",
    "\n",
    "  def compute_params(self, inputs):\n",
    "    kmeans = KMeans(n_clusters=self.num_units, random_state=0, copy_x=True).fit(inputs)\n",
    "    self.centers = kmeans.cluster_centers_\n",
    "    d_max = ComputeMaxDistance(self.centers, self.centers)\n",
    "    self.sigma = d_max / (math.sqrt(2 * self.centers.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import utils\n",
    "import rbf_layer\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                   read data                                  #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "# data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "data = \"boston.csv\"\n",
    "raw_df = pd.read_csv(data, sep=\"\\s+\", skiprows=22, header=None)\n",
    "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "y = raw_df.values[1::2, 2]\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                normalize data                                #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "preprocessing.scale(X, copy=False)\n",
    "preprocessing.scale(y, copy=False)\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                      split data to training and testing                      #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=0)\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "hidden_size = int(0.1 * n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rbf_48/sub:0\", shape=(37, 13), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rbf_layer_ = RBF(hidden_size)\n",
    "rbf_layer_.compute_params(X_train)\n",
    "# rbf_layer_.compute_params(X_train)\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Input(shape=(13,)))\n",
    "# model.add(layers.Dense(12, input_shape=(13,), activation='relu'))\n",
    "model.add(rbf_layer_)\n",
    "# model.add(layers.Dense(8, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile()\n",
    "# model.fit(X_train, y_train, epochs=5, batch_size=10)\n",
    "\n",
    "# train model\n",
    "# history = model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5356340e-01, 3.4652334e-02, 2.0106247e-02, 3.4650344e-02,\n",
       "       1.9822607e-02, 6.2260521e-03, 4.9070187e-02, 1.1567194e-01,\n",
       "       3.8614171e+00, 8.3840352e-01, 4.4612970e-02, 1.2057885e-02,\n",
       "       2.3655333e-01, 4.2094436e-02, 8.3106123e-02, 1.0509519e-02,\n",
       "       3.6319152e-01, 2.8838949e+01, 1.6627885e+00, 3.3018343e-02,\n",
       "       1.2861995e-01, 8.5926950e-02, 4.7045428e-02, 3.6514189e-02,\n",
       "       6.5708494e-01, 1.0345719e-01, 8.2592636e-02, 1.2584703e+02,\n",
       "       4.4353214e-01, 1.6439890e-02, 3.3533174e-01, 4.1287810e-01,\n",
       "       3.7816346e-02, 1.4827551e-02, 1.7922504e-01, 4.5908085e+01,\n",
       "       1.2840350e-01], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# model.summary()\n",
    "model.predict(X_train[0])\n",
    "# a = tf.constant([1, 2])\n",
    "# print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  0  0]\n",
      " [-3 -3 -3]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3 3 3]\n",
      " [0 0 0]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[6 6 6]\n",
      " [3 3 3]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# t = tf.constant([3, 2])\n",
    "\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "centers = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# for x_ in x:\n",
    "#     for c in centers:\n",
    "#         print(-np.linalg.norm(c - x_)**2 / 2)\n",
    "\n",
    "for x_ in x:\n",
    "    print(x_-centers)\n",
    "\n",
    "# print([(-np.linalg.norm(c - x)**2 / 2) for c in centers])\n",
    "\n",
    "# x = tf.expand_dims(tf.constant([[1, 2, 3],[4, 5, 6]]), -1)\n",
    "# print(x.numpy())\n",
    "\n",
    "# centers = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# sigma = 1\n",
    "\n",
    "# res = tf.constant([math.exp(-np.linalg.norm(x - c)**2 / (2 * sigma**2)) for c in centers])\n",
    "# print(res)\n",
    "\n",
    "# for t_ in t:\n",
    "#     print(t_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
